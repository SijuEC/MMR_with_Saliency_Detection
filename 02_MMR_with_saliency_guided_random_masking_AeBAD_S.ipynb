{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d51f91f6-e80f-4b2a-a72e-064b2373f90a",
   "metadata": {},
   "source": [
    "This jupyter notebook contains the steps to install the required depedencies and run the MMR model in a linux machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35dd4912-e56e-483b-9db4-f2a1eda52f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: opencv-python 4.6.0.66\n",
      "Uninstalling opencv-python-4.6.0.66:\n",
      "  Successfully uninstalled opencv-python-4.6.0.66\n",
      "\u001b[33mWARNING: Skipping opencv-contrib-python as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Uninstalling opencv-python and opencv-contrib-python to allow the installation of the dependencies as per the requirements file\n",
    "!pip uninstall opencv-python opencv-contrib-python -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e58431fb-5c87-4c8a-bc6d-55f13382a6d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fvcore==0.1.5.post20221221\n",
      "  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m977.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: matplotlib==3.6.1 in /usr/local/lib/python3.9/dist-packages (from -r /notebooks/MMR/requirements.txt (line 2)) (3.6.1)\n",
      "Requirement already satisfied: numpy==1.23.4 in /usr/local/lib/python3.9/dist-packages (from -r /notebooks/MMR/requirements.txt (line 3)) (1.23.4)\n",
      "Collecting opencv-contrib-python==4.9.0.80\n",
      "  Downloading opencv_contrib_python-4.9.0.80-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (68.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.3/68.3 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pandas==1.5.0 in /usr/local/lib/python3.9/dist-packages (from -r /notebooks/MMR/requirements.txt (line 5)) (1.5.0)\n",
      "Requirement already satisfied: scikit-learn==1.1.2 in /usr/local/lib/python3.9/dist-packages (from -r /notebooks/MMR/requirements.txt (line 6)) (1.1.2)\n",
      "Requirement already satisfied: scipy==1.9.2 in /usr/local/lib/python3.9/dist-packages (from -r /notebooks/MMR/requirements.txt (line 7)) (1.9.2)\n",
      "Requirement already satisfied: seaborn==0.12.0 in /usr/local/lib/python3.9/dist-packages (from -r /notebooks/MMR/requirements.txt (line 8)) (0.12.0)\n",
      "Collecting timm==0.9.16\n",
      "  Downloading timm-0.9.16-py3-none-any.whl (2.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torch==1.12.1+cu116 in /usr/local/lib/python3.9/dist-packages (from -r /notebooks/MMR/requirements.txt (line 10)) (1.12.1+cu116)\n",
      "Requirement already satisfied: torchvision==0.13.1+cu116 in /usr/local/lib/python3.9/dist-packages (from -r /notebooks/MMR/requirements.txt (line 11)) (0.13.1+cu116)\n",
      "Collecting yacs>=0.1.6\n",
      "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from fvcore==0.1.5.post20221221->-r /notebooks/MMR/requirements.txt (line 1)) (5.4.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from fvcore==0.1.5.post20221221->-r /notebooks/MMR/requirements.txt (line 1)) (4.64.1)\n",
      "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.9/dist-packages (from fvcore==0.1.5.post20221221->-r /notebooks/MMR/requirements.txt (line 1)) (2.2.0)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.9/dist-packages (from fvcore==0.1.5.post20221221->-r /notebooks/MMR/requirements.txt (line 1)) (9.2.0)\n",
      "Requirement already satisfied: tabulate in /usr/local/lib/python3.9/dist-packages (from fvcore==0.1.5.post20221221->-r /notebooks/MMR/requirements.txt (line 1)) (0.9.0)\n",
      "Collecting iopath>=0.1.7\n",
      "  Downloading iopath-0.1.10.tar.gz (42 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib==3.6.1->-r /notebooks/MMR/requirements.txt (line 2)) (23.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib==3.6.1->-r /notebooks/MMR/requirements.txt (line 2)) (1.0.7)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib==3.6.1->-r /notebooks/MMR/requirements.txt (line 2)) (4.38.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib==3.6.1->-r /notebooks/MMR/requirements.txt (line 2)) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib==3.6.1->-r /notebooks/MMR/requirements.txt (line 2)) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib==3.6.1->-r /notebooks/MMR/requirements.txt (line 2)) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib==3.6.1->-r /notebooks/MMR/requirements.txt (line 2)) (0.11.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas==1.5.0->-r /notebooks/MMR/requirements.txt (line 5)) (2022.7.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn==1.1.2->-r /notebooks/MMR/requirements.txt (line 6)) (3.1.0)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn==1.1.2->-r /notebooks/MMR/requirements.txt (line 6)) (1.2.0)\n",
      "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.9/dist-packages (from timm==0.9.16->-r /notebooks/MMR/requirements.txt (line 9)) (0.12.0)\n",
      "Collecting safetensors\n",
      "  Downloading safetensors-0.4.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch==1.12.1+cu116->-r /notebooks/MMR/requirements.txt (line 10)) (4.4.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torchvision==0.13.1+cu116->-r /notebooks/MMR/requirements.txt (line 11)) (2.28.2)\n",
      "Collecting portalocker\n",
      "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib==3.6.1->-r /notebooks/MMR/requirements.txt (line 2)) (1.14.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from huggingface_hub->timm==0.9.16->-r /notebooks/MMR/requirements.txt (line 9)) (3.9.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision==0.13.1+cu116->-r /notebooks/MMR/requirements.txt (line 11)) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision==0.13.1+cu116->-r /notebooks/MMR/requirements.txt (line 11)) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->torchvision==0.13.1+cu116->-r /notebooks/MMR/requirements.txt (line 11)) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->torchvision==0.13.1+cu116->-r /notebooks/MMR/requirements.txt (line 11)) (2019.11.28)\n",
      "Building wheels for collected packages: fvcore, iopath\n",
      "  Building wheel for fvcore (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61406 sha256=e6d59c8bea396c8c5f7d614f6857a1ed6a4be091f230a2222a008f8027b05fb4\n",
      "  Stored in directory: /root/.cache/pip/wheels/51/0c/22/61b6d299cd3d20d3a6a71e82477d504c03b81058d96776f4b7\n",
      "  Building wheel for iopath (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31532 sha256=006310dad735b56e44d81799b5d45f45f6490d1eb1ee1fb79b5dc2e083807b8a\n",
      "  Stored in directory: /root/.cache/pip/wheels/2f/ce/ac/07529e6caba9b9c9c78a3cdae0a21c52ed14b37f98599eab74\n",
      "Successfully built fvcore iopath\n",
      "Installing collected packages: yacs, safetensors, portalocker, opencv-contrib-python, iopath, timm, fvcore\n",
      "Successfully installed fvcore-0.1.5.post20221221 iopath-0.1.10 opencv-contrib-python-4.9.0.80 portalocker-2.8.2 safetensors-0.4.2 timm-0.9.16 yacs-0.1.8\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Installing the required dependencies as per the requirements file\n",
    "!pip install -r /notebooks/MMR/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8bf88916-ea1f-449b-8e1a-de7888859540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the AeBAD_S_run.sh as an executable\n",
    "!chmod +x /notebooks/MMR/AeBAD_S_run.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d851896d-5d1d-476e-b84d-d74421fb2ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02/29 05:32:56][INFO] main.py:   26: {'DATASET': {'domain_shift_category': 'same',\n",
      "             'imagesize': 224,\n",
      "             'name': 'aebad_S',\n",
      "             'resize': 256,\n",
      "             'subdatasets': ['AeBAD_S']},\n",
      " 'NUM_GPUS': 1,\n",
      " 'OUTPUT_DIR': './log_MMR_AeBAD_S_54',\n",
      " 'RNG_SEED': 54,\n",
      " 'TEST': {'VISUALIZE': CfgNode({'Random_sample': True, 'Sample_num': 40}),\n",
      "          'dataset_path': '/notebooks/AeBAD',\n",
      "          'enable': False,\n",
      "          'method': 'MMR',\n",
      "          'pixel_mode_verify': True,\n",
      "          'save_segmentation_images': True,\n",
      "          'save_video_segmentation_images': False},\n",
      " 'TEST_SETUPS': CfgNode({'batch_size': 32}),\n",
      " 'TRAIN': {'MMR': {'DA_low_limit': 0.7,\n",
      "                   'DA_up_limit': 1.0,\n",
      "                   'FPN_output_dim': (256, 512, 1024),\n",
      "                   'feature_compression': False,\n",
      "                   'finetune_mask_ratio': 0.6,\n",
      "                   'layers_to_extract_from': ['layer1', 'layer2', 'layer3'],\n",
      "                   'load_pretrain_model': True,\n",
      "                   'model_chkpt': '/notebooks/MMR/mae_visualize_vit_base.pth',\n",
      "                   'scale_factors': (4.0, 2.0, 1.0),\n",
      "                   'test_mask_ratio': 0.0},\n",
      "           'backbone': 'wideresnet50',\n",
      "           'dataset_path': '/notebooks/AeBAD',\n",
      "           'enable': True,\n",
      "           'method': 'MMR',\n",
      "           'save_model': False},\n",
      " 'TRAIN_SETUPS': {'batch_size': 16,\n",
      "                  'epochs': 200,\n",
      "                  'learning_rate': 0.001,\n",
      "                  'num_workers': 8,\n",
      "                  'warmup_epochs': 50,\n",
      "                  'weight_decay': 0.05}}\n",
      "[02/29 05:32:56][INFO] main.py:   27: path_to_config is /notebooks/MMR/method_config/AeBAD_S/MMR.yaml\n",
      "[02/29 05:32:56][INFO] main.py:   31: start training!\n",
      "[02/29 05:32:56][INFO] train.py:   27: load dataset!\n",
      "[02/29 05:32:57][INFO] train.py:   55: current individual_dataloader is aebad_S_AeBAD_S.\n",
      "[02/29 05:32:57][INFO] train.py:   56: the data in current individual_dataloader aebad_S_AeBAD_S are 521.\n",
      "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=Wide_ResNet50_2_Weights.IMAGENET1K_V1`. You can also use `weights=Wide_ResNet50_2_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/wide_resnet50_2-95faca4d.pth\" to /root/.cache/torch/hub/checkpoints/wide_resnet50_2-95faca4d.pth\n",
      "100%|█████████████████████████████████████████| 132M/132M [02:27<00:00, 937kB/s]\n",
      "[02/29 05:37:47][INFO] train.py:   73: train the decoder FPN of MMR from scratch!\n",
      "[02/29 05:37:47][INFO] train.py:   76: MAE load meg: _IncompatibleKeys(missing_keys=['decoder_FPN_mask_token', 'decoder_FPN_pos_embed', 'simfp_2.0.weight', 'simfp_2.0.bias', 'simfp_2.1.weight', 'simfp_2.1.bias', 'simfp_2.3.weight', 'simfp_2.3.bias', 'simfp_2.4.weight', 'simfp_2.4.norm.weight', 'simfp_2.4.norm.bias', 'simfp_2.5.weight', 'simfp_2.5.norm.weight', 'simfp_2.5.norm.bias', 'simfp_3.0.weight', 'simfp_3.0.bias', 'simfp_3.1.weight', 'simfp_3.1.norm.weight', 'simfp_3.1.norm.bias', 'simfp_3.2.weight', 'simfp_3.2.norm.weight', 'simfp_3.2.norm.bias', 'simfp_4.0.weight', 'simfp_4.0.norm.weight', 'simfp_4.0.norm.bias', 'simfp_4.1.weight', 'simfp_4.1.norm.weight', 'simfp_4.1.norm.bias'], unexpected_keys=[])\n",
      "[02/29 05:38:36][INFO] MMR_pipeline.py:   73: epoch [1/200], loss:3.0119\n",
      "[02/29 05:39:13][INFO] MMR_pipeline.py:   73: epoch [2/200], loss:2.0433\n",
      "[02/29 05:39:51][INFO] MMR_pipeline.py:   73: epoch [3/200], loss:1.4613\n",
      "[02/29 05:40:30][INFO] MMR_pipeline.py:   73: epoch [4/200], loss:1.3667\n",
      "[02/29 05:41:08][INFO] MMR_pipeline.py:   73: epoch [5/200], loss:1.2890\n",
      "[02/29 05:41:47][INFO] MMR_pipeline.py:   73: epoch [6/200], loss:1.2244\n",
      "[02/29 05:42:25][INFO] MMR_pipeline.py:   73: epoch [7/200], loss:1.1725\n",
      "[02/29 05:43:04][INFO] MMR_pipeline.py:   73: epoch [8/200], loss:1.1279\n",
      "[02/29 05:43:43][INFO] MMR_pipeline.py:   73: epoch [9/200], loss:1.0896\n",
      "[02/29 05:44:21][INFO] MMR_pipeline.py:   73: epoch [10/200], loss:1.0505\n",
      "[02/29 05:44:59][INFO] MMR_pipeline.py:   73: epoch [11/200], loss:1.0194\n",
      "[02/29 05:45:38][INFO] MMR_pipeline.py:   73: epoch [12/200], loss:0.9885\n",
      "[02/29 05:46:16][INFO] MMR_pipeline.py:   73: epoch [13/200], loss:0.9540\n",
      "[02/29 05:46:55][INFO] MMR_pipeline.py:   73: epoch [14/200], loss:0.9255\n",
      "[02/29 05:47:34][INFO] MMR_pipeline.py:   73: epoch [15/200], loss:0.8931\n",
      "[02/29 05:48:13][INFO] MMR_pipeline.py:   73: epoch [16/200], loss:0.8613\n",
      "[02/29 05:48:51][INFO] MMR_pipeline.py:   73: epoch [17/200], loss:0.8298\n",
      "[02/29 05:49:30][INFO] MMR_pipeline.py:   73: epoch [18/200], loss:0.8003\n",
      "[02/29 05:50:08][INFO] MMR_pipeline.py:   73: epoch [19/200], loss:0.7688\n",
      "[02/29 05:50:46][INFO] MMR_pipeline.py:   73: epoch [20/200], loss:0.7390\n",
      "[02/29 05:51:25][INFO] MMR_pipeline.py:   73: epoch [21/200], loss:0.7072\n",
      "[02/29 05:52:03][INFO] MMR_pipeline.py:   73: epoch [22/200], loss:0.6782\n",
      "[02/29 05:52:42][INFO] MMR_pipeline.py:   73: epoch [23/200], loss:0.6473\n",
      "[02/29 05:53:20][INFO] MMR_pipeline.py:   73: epoch [24/200], loss:0.6177\n",
      "[02/29 05:53:58][INFO] MMR_pipeline.py:   73: epoch [25/200], loss:0.5915\n",
      "[02/29 05:54:37][INFO] MMR_pipeline.py:   73: epoch [26/200], loss:0.5646\n",
      "[02/29 05:55:14][INFO] MMR_pipeline.py:   73: epoch [27/200], loss:0.5351\n",
      "[02/29 05:55:52][INFO] MMR_pipeline.py:   73: epoch [28/200], loss:0.5088\n",
      "[02/29 05:56:31][INFO] MMR_pipeline.py:   73: epoch [29/200], loss:0.4839\n",
      "[02/29 05:57:09][INFO] MMR_pipeline.py:   73: epoch [30/200], loss:0.4602\n",
      "[02/29 05:57:48][INFO] MMR_pipeline.py:   73: epoch [31/200], loss:0.4390\n",
      "[02/29 05:58:26][INFO] MMR_pipeline.py:   73: epoch [32/200], loss:0.4173\n",
      "[02/29 05:59:05][INFO] MMR_pipeline.py:   73: epoch [33/200], loss:0.3959\n",
      "[02/29 05:59:43][INFO] MMR_pipeline.py:   73: epoch [34/200], loss:0.3785\n",
      "[02/29 06:00:21][INFO] MMR_pipeline.py:   73: epoch [35/200], loss:0.3623\n",
      "[02/29 06:00:59][INFO] MMR_pipeline.py:   73: epoch [36/200], loss:0.3477\n",
      "[02/29 06:01:38][INFO] MMR_pipeline.py:   73: epoch [37/200], loss:0.3350\n",
      "[02/29 06:02:16][INFO] MMR_pipeline.py:   73: epoch [38/200], loss:0.3238\n",
      "[02/29 06:02:54][INFO] MMR_pipeline.py:   73: epoch [39/200], loss:0.3158\n",
      "[02/29 06:03:33][INFO] MMR_pipeline.py:   73: epoch [40/200], loss:0.3085\n",
      "[02/29 06:04:11][INFO] MMR_pipeline.py:   73: epoch [41/200], loss:0.3027\n",
      "[02/29 06:04:48][INFO] MMR_pipeline.py:   73: epoch [42/200], loss:0.2972\n",
      "[02/29 06:05:27][INFO] MMR_pipeline.py:   73: epoch [43/200], loss:0.2951\n",
      "[02/29 06:06:04][INFO] MMR_pipeline.py:   73: epoch [44/200], loss:0.2926\n",
      "[02/29 06:06:43][INFO] MMR_pipeline.py:   73: epoch [45/200], loss:0.2912\n",
      "[02/29 06:07:21][INFO] MMR_pipeline.py:   73: epoch [46/200], loss:0.2894\n",
      "[02/29 06:08:00][INFO] MMR_pipeline.py:   73: epoch [47/200], loss:0.2891\n",
      "[02/29 06:08:38][INFO] MMR_pipeline.py:   73: epoch [48/200], loss:0.2882\n",
      "[02/29 06:09:17][INFO] MMR_pipeline.py:   73: epoch [49/200], loss:0.2883\n",
      "[02/29 06:09:17][INFO] MMR_pipeline.py:   45: current lr is 0.00098\n",
      "[02/29 06:09:55][INFO] MMR_pipeline.py:   73: epoch [50/200], loss:0.2860\n",
      "[02/29 06:10:33][INFO] MMR_pipeline.py:   73: epoch [51/200], loss:0.2851\n",
      "[02/29 06:11:12][INFO] MMR_pipeline.py:   73: epoch [52/200], loss:0.2863\n",
      "[02/29 06:11:50][INFO] MMR_pipeline.py:   73: epoch [53/200], loss:0.2838\n",
      "[02/29 06:12:28][INFO] MMR_pipeline.py:   73: epoch [54/200], loss:0.2826\n",
      "[02/29 06:13:07][INFO] MMR_pipeline.py:   73: epoch [55/200], loss:0.2811\n",
      "[02/29 06:13:45][INFO] MMR_pipeline.py:   73: epoch [56/200], loss:0.2803\n",
      "[02/29 06:14:23][INFO] MMR_pipeline.py:   73: epoch [57/200], loss:0.2812\n",
      "[02/29 06:15:02][INFO] MMR_pipeline.py:   73: epoch [58/200], loss:0.2784\n",
      "[02/29 06:15:41][INFO] MMR_pipeline.py:   73: epoch [59/200], loss:0.2768\n",
      "[02/29 06:16:20][INFO] MMR_pipeline.py:   73: epoch [60/200], loss:0.2764\n",
      "[02/29 06:16:58][INFO] MMR_pipeline.py:   73: epoch [61/200], loss:0.2743\n",
      "[02/29 06:17:37][INFO] MMR_pipeline.py:   73: epoch [62/200], loss:0.2750\n",
      "[02/29 06:18:16][INFO] MMR_pipeline.py:   73: epoch [63/200], loss:0.2749\n",
      "[02/29 06:18:54][INFO] MMR_pipeline.py:   73: epoch [64/200], loss:0.2741\n",
      "[02/29 06:19:33][INFO] MMR_pipeline.py:   73: epoch [65/200], loss:0.2722\n",
      "[02/29 06:20:12][INFO] MMR_pipeline.py:   73: epoch [66/200], loss:0.2711\n",
      "[02/29 06:20:50][INFO] MMR_pipeline.py:   73: epoch [67/200], loss:0.2728\n",
      "[02/29 06:21:30][INFO] MMR_pipeline.py:   73: epoch [68/200], loss:0.2707\n",
      "[02/29 06:22:09][INFO] MMR_pipeline.py:   73: epoch [69/200], loss:0.2678\n",
      "[02/29 06:22:47][INFO] MMR_pipeline.py:   73: epoch [70/200], loss:0.2688\n",
      "[02/29 06:23:25][INFO] MMR_pipeline.py:   73: epoch [71/200], loss:0.2693\n",
      "[02/29 06:24:04][INFO] MMR_pipeline.py:   73: epoch [72/200], loss:0.2681\n",
      "[02/29 06:24:42][INFO] MMR_pipeline.py:   73: epoch [73/200], loss:0.2694\n",
      "[02/29 06:25:21][INFO] MMR_pipeline.py:   73: epoch [74/200], loss:0.2663\n",
      "[02/29 06:25:59][INFO] MMR_pipeline.py:   73: epoch [75/200], loss:0.2661\n",
      "[02/29 06:26:38][INFO] MMR_pipeline.py:   73: epoch [76/200], loss:0.2661\n",
      "[02/29 06:27:16][INFO] MMR_pipeline.py:   73: epoch [77/200], loss:0.2654\n",
      "[02/29 06:27:55][INFO] MMR_pipeline.py:   73: epoch [78/200], loss:0.2652\n",
      "[02/29 06:28:34][INFO] MMR_pipeline.py:   73: epoch [79/200], loss:0.2628\n",
      "[02/29 06:29:12][INFO] MMR_pipeline.py:   73: epoch [80/200], loss:0.2629\n",
      "[02/29 06:29:51][INFO] MMR_pipeline.py:   73: epoch [81/200], loss:0.2633\n",
      "[02/29 06:30:30][INFO] MMR_pipeline.py:   73: epoch [82/200], loss:0.2615\n",
      "[02/29 06:31:08][INFO] MMR_pipeline.py:   73: epoch [83/200], loss:0.2618\n",
      "[02/29 06:31:47][INFO] MMR_pipeline.py:   73: epoch [84/200], loss:0.2612\n",
      "[02/29 06:32:26][INFO] MMR_pipeline.py:   73: epoch [85/200], loss:0.2621\n",
      "[02/29 06:33:05][INFO] MMR_pipeline.py:   73: epoch [86/200], loss:0.2616\n",
      "[02/29 06:33:43][INFO] MMR_pipeline.py:   73: epoch [87/200], loss:0.2599\n",
      "[02/29 06:34:22][INFO] MMR_pipeline.py:   73: epoch [88/200], loss:0.2590\n",
      "[02/29 06:35:01][INFO] MMR_pipeline.py:   73: epoch [89/200], loss:0.2598\n",
      "[02/29 06:35:38][INFO] MMR_pipeline.py:   73: epoch [90/200], loss:0.2586\n",
      "[02/29 06:36:17][INFO] MMR_pipeline.py:   73: epoch [91/200], loss:0.2592\n",
      "[02/29 06:36:55][INFO] MMR_pipeline.py:   73: epoch [92/200], loss:0.2577\n",
      "[02/29 06:37:34][INFO] MMR_pipeline.py:   73: epoch [93/200], loss:0.2575\n",
      "[02/29 06:38:12][INFO] MMR_pipeline.py:   73: epoch [94/200], loss:0.2564\n",
      "[02/29 06:38:50][INFO] MMR_pipeline.py:   73: epoch [95/200], loss:0.2575\n",
      "[02/29 06:39:28][INFO] MMR_pipeline.py:   73: epoch [96/200], loss:0.2562\n",
      "[02/29 06:40:07][INFO] MMR_pipeline.py:   73: epoch [97/200], loss:0.2567\n",
      "[02/29 06:40:45][INFO] MMR_pipeline.py:   73: epoch [98/200], loss:0.2557\n",
      "[02/29 06:41:23][INFO] MMR_pipeline.py:   73: epoch [99/200], loss:0.2572\n",
      "[02/29 06:41:23][INFO] MMR_pipeline.py:   45: current lr is 0.00100\n",
      "[02/29 06:42:02][INFO] MMR_pipeline.py:   73: epoch [100/200], loss:0.2550\n",
      "[02/29 06:42:40][INFO] MMR_pipeline.py:   73: epoch [101/200], loss:0.2549\n",
      "[02/29 06:43:18][INFO] MMR_pipeline.py:   73: epoch [102/200], loss:0.2536\n",
      "[02/29 06:43:56][INFO] MMR_pipeline.py:   73: epoch [103/200], loss:0.2543\n",
      "[02/29 06:44:33][INFO] MMR_pipeline.py:   73: epoch [104/200], loss:0.2533\n",
      "[02/29 06:45:11][INFO] MMR_pipeline.py:   73: epoch [105/200], loss:0.2532\n",
      "[02/29 06:45:50][INFO] MMR_pipeline.py:   73: epoch [106/200], loss:0.2533\n",
      "[02/29 06:46:28][INFO] MMR_pipeline.py:   73: epoch [107/200], loss:0.2529\n",
      "[02/29 06:47:07][INFO] MMR_pipeline.py:   73: epoch [108/200], loss:0.2521\n",
      "[02/29 06:47:45][INFO] MMR_pipeline.py:   73: epoch [109/200], loss:0.2524\n",
      "[02/29 06:48:23][INFO] MMR_pipeline.py:   73: epoch [110/200], loss:0.2522\n",
      "[02/29 06:49:02][INFO] MMR_pipeline.py:   73: epoch [111/200], loss:0.2519\n",
      "[02/29 06:49:41][INFO] MMR_pipeline.py:   73: epoch [112/200], loss:0.2511\n",
      "[02/29 06:50:18][INFO] MMR_pipeline.py:   73: epoch [113/200], loss:0.2504\n",
      "[02/29 06:50:56][INFO] MMR_pipeline.py:   73: epoch [114/200], loss:0.2504\n",
      "[02/29 06:51:35][INFO] MMR_pipeline.py:   73: epoch [115/200], loss:0.2505\n",
      "[02/29 06:52:13][INFO] MMR_pipeline.py:   73: epoch [116/200], loss:0.2516\n",
      "[02/29 06:52:52][INFO] MMR_pipeline.py:   73: epoch [117/200], loss:0.2501\n",
      "[02/29 06:53:30][INFO] MMR_pipeline.py:   73: epoch [118/200], loss:0.2505\n",
      "[02/29 06:54:08][INFO] MMR_pipeline.py:   73: epoch [119/200], loss:0.2494\n",
      "[02/29 06:54:47][INFO] MMR_pipeline.py:   73: epoch [120/200], loss:0.2451\n",
      "[02/29 06:55:26][INFO] MMR_pipeline.py:   73: epoch [121/200], loss:0.2415\n",
      "[02/29 06:56:05][INFO] MMR_pipeline.py:   73: epoch [122/200], loss:0.2397\n",
      "[02/29 06:56:43][INFO] MMR_pipeline.py:   73: epoch [123/200], loss:0.2391\n",
      "[02/29 06:57:22][INFO] MMR_pipeline.py:   73: epoch [124/200], loss:0.2383\n",
      "[02/29 06:58:01][INFO] MMR_pipeline.py:   73: epoch [125/200], loss:0.2384\n",
      "[02/29 06:58:41][INFO] MMR_pipeline.py:   73: epoch [126/200], loss:0.2376\n",
      "[02/29 06:59:21][INFO] MMR_pipeline.py:   73: epoch [127/200], loss:0.2371\n",
      "[02/29 07:00:00][INFO] MMR_pipeline.py:   73: epoch [128/200], loss:0.2360\n",
      "[02/29 07:00:38][INFO] MMR_pipeline.py:   73: epoch [129/200], loss:0.2358\n",
      "[02/29 07:01:16][INFO] MMR_pipeline.py:   73: epoch [130/200], loss:0.2359\n",
      "[02/29 07:01:55][INFO] MMR_pipeline.py:   73: epoch [131/200], loss:0.2350\n",
      "[02/29 07:02:32][INFO] MMR_pipeline.py:   73: epoch [132/200], loss:0.2350\n",
      "[02/29 07:03:11][INFO] MMR_pipeline.py:   73: epoch [133/200], loss:0.2354\n",
      "[02/29 07:03:50][INFO] MMR_pipeline.py:   73: epoch [134/200], loss:0.2353\n",
      "[02/29 07:04:28][INFO] MMR_pipeline.py:   73: epoch [135/200], loss:0.2346\n",
      "[02/29 07:05:07][INFO] MMR_pipeline.py:   73: epoch [136/200], loss:0.2357\n",
      "[02/29 07:05:46][INFO] MMR_pipeline.py:   73: epoch [137/200], loss:0.2348\n",
      "[02/29 07:06:24][INFO] MMR_pipeline.py:   73: epoch [138/200], loss:0.2353\n",
      "[02/29 07:07:03][INFO] MMR_pipeline.py:   73: epoch [139/200], loss:0.2344\n",
      "[02/29 07:07:41][INFO] MMR_pipeline.py:   73: epoch [140/200], loss:0.2337\n",
      "[02/29 07:08:20][INFO] MMR_pipeline.py:   73: epoch [141/200], loss:0.2332\n",
      "[02/29 07:08:58][INFO] MMR_pipeline.py:   73: epoch [142/200], loss:0.2347\n",
      "[02/29 07:09:36][INFO] MMR_pipeline.py:   73: epoch [143/200], loss:0.2343\n",
      "[02/29 07:10:15][INFO] MMR_pipeline.py:   73: epoch [144/200], loss:0.2332\n",
      "[02/29 07:10:54][INFO] MMR_pipeline.py:   73: epoch [145/200], loss:0.2344\n",
      "[02/29 07:11:32][INFO] MMR_pipeline.py:   73: epoch [146/200], loss:0.2332\n",
      "[02/29 07:12:10][INFO] MMR_pipeline.py:   73: epoch [147/200], loss:0.2334\n",
      "[02/29 07:12:48][INFO] MMR_pipeline.py:   73: epoch [148/200], loss:0.2320\n",
      "[02/29 07:13:26][INFO] MMR_pipeline.py:   73: epoch [149/200], loss:0.2327\n",
      "[02/29 07:13:26][INFO] MMR_pipeline.py:   45: current lr is 0.00010\n",
      "[02/29 07:14:05][INFO] MMR_pipeline.py:   73: epoch [150/200], loss:0.2331\n",
      "[02/29 07:14:43][INFO] MMR_pipeline.py:   73: epoch [151/200], loss:0.2328\n",
      "[02/29 07:15:22][INFO] MMR_pipeline.py:   73: epoch [152/200], loss:0.2330\n",
      "[02/29 07:16:00][INFO] MMR_pipeline.py:   73: epoch [153/200], loss:0.2329\n",
      "[02/29 07:16:38][INFO] MMR_pipeline.py:   73: epoch [154/200], loss:0.2338\n",
      "[02/29 07:17:17][INFO] MMR_pipeline.py:   73: epoch [155/200], loss:0.2333\n",
      "[02/29 07:17:55][INFO] MMR_pipeline.py:   73: epoch [156/200], loss:0.2317\n",
      "[02/29 07:18:33][INFO] MMR_pipeline.py:   73: epoch [157/200], loss:0.2327\n",
      "[02/29 07:19:12][INFO] MMR_pipeline.py:   73: epoch [158/200], loss:0.2330\n",
      "[02/29 07:19:50][INFO] MMR_pipeline.py:   73: epoch [159/200], loss:0.2327\n",
      "[02/29 07:20:29][INFO] MMR_pipeline.py:   73: epoch [160/200], loss:0.2316\n",
      "[02/29 07:21:07][INFO] MMR_pipeline.py:   73: epoch [161/200], loss:0.2310\n",
      "[02/29 07:21:45][INFO] MMR_pipeline.py:   73: epoch [162/200], loss:0.2313\n",
      "[02/29 07:22:24][INFO] MMR_pipeline.py:   73: epoch [163/200], loss:0.2309\n",
      "[02/29 07:23:02][INFO] MMR_pipeline.py:   73: epoch [164/200], loss:0.2312\n",
      "[02/29 07:23:41][INFO] MMR_pipeline.py:   73: epoch [165/200], loss:0.2318\n",
      "[02/29 07:24:19][INFO] MMR_pipeline.py:   73: epoch [166/200], loss:0.2303\n",
      "[02/29 07:24:56][INFO] MMR_pipeline.py:   73: epoch [167/200], loss:0.2312\n",
      "[02/29 07:25:35][INFO] MMR_pipeline.py:   73: epoch [168/200], loss:0.2319\n",
      "[02/29 07:26:13][INFO] MMR_pipeline.py:   73: epoch [169/200], loss:0.2312\n",
      "[02/29 07:26:52][INFO] MMR_pipeline.py:   73: epoch [170/200], loss:0.2313\n",
      "[02/29 07:27:30][INFO] MMR_pipeline.py:   73: epoch [171/200], loss:0.2310\n",
      "[02/29 07:28:09][INFO] MMR_pipeline.py:   73: epoch [172/200], loss:0.2321\n",
      "[02/29 07:28:47][INFO] MMR_pipeline.py:   73: epoch [173/200], loss:0.2322\n",
      "[02/29 07:29:26][INFO] MMR_pipeline.py:   73: epoch [174/200], loss:0.2300\n",
      "[02/29 07:30:05][INFO] MMR_pipeline.py:   73: epoch [175/200], loss:0.2311\n",
      "[02/29 07:30:43][INFO] MMR_pipeline.py:   73: epoch [176/200], loss:0.2311\n",
      "[02/29 07:31:22][INFO] MMR_pipeline.py:   73: epoch [177/200], loss:0.2303\n",
      "[02/29 07:32:00][INFO] MMR_pipeline.py:   73: epoch [178/200], loss:0.2315\n",
      "[02/29 07:32:38][INFO] MMR_pipeline.py:   73: epoch [179/200], loss:0.2307\n",
      "[02/29 07:33:17][INFO] MMR_pipeline.py:   73: epoch [180/200], loss:0.2310\n",
      "[02/29 07:33:55][INFO] MMR_pipeline.py:   73: epoch [181/200], loss:0.2307\n",
      "[02/29 07:34:34][INFO] MMR_pipeline.py:   73: epoch [182/200], loss:0.2303\n",
      "[02/29 07:35:13][INFO] MMR_pipeline.py:   73: epoch [183/200], loss:0.2312\n",
      "[02/29 07:35:51][INFO] MMR_pipeline.py:   73: epoch [184/200], loss:0.2306\n",
      "[02/29 07:36:29][INFO] MMR_pipeline.py:   73: epoch [185/200], loss:0.2299\n",
      "[02/29 07:37:08][INFO] MMR_pipeline.py:   73: epoch [186/200], loss:0.2315\n",
      "[02/29 07:37:46][INFO] MMR_pipeline.py:   73: epoch [187/200], loss:0.2301\n",
      "[02/29 07:38:24][INFO] MMR_pipeline.py:   73: epoch [188/200], loss:0.2321\n",
      "[02/29 07:39:03][INFO] MMR_pipeline.py:   73: epoch [189/200], loss:0.2305\n",
      "[02/29 07:39:40][INFO] MMR_pipeline.py:   73: epoch [190/200], loss:0.2316\n",
      "[02/29 07:40:19][INFO] MMR_pipeline.py:   73: epoch [191/200], loss:0.2315\n",
      "[02/29 07:40:57][INFO] MMR_pipeline.py:   73: epoch [192/200], loss:0.2314\n",
      "[02/29 07:41:35][INFO] MMR_pipeline.py:   73: epoch [193/200], loss:0.2308\n",
      "[02/29 07:42:13][INFO] MMR_pipeline.py:   73: epoch [194/200], loss:0.2305\n",
      "[02/29 07:42:52][INFO] MMR_pipeline.py:   73: epoch [195/200], loss:0.2310\n",
      "[02/29 07:43:29][INFO] MMR_pipeline.py:   73: epoch [196/200], loss:0.2307\n",
      "[02/29 07:44:08][INFO] MMR_pipeline.py:   73: epoch [197/200], loss:0.2317\n",
      "[02/29 07:44:46][INFO] MMR_pipeline.py:   73: epoch [198/200], loss:0.2306\n",
      "[02/29 07:45:25][INFO] MMR_pipeline.py:   73: epoch [199/200], loss:0.2303\n",
      "[02/29 07:45:25][INFO] MMR_pipeline.py:   45: current lr is 0.00001\n",
      "[02/29 07:46:03][INFO] MMR_pipeline.py:   73: epoch [200/200], loss:0.2308\n",
      "[02/29 07:46:03][INFO] train.py:  105: current domain shift mode is same!\n",
      "[02/29 07:46:03][INFO] train.py:  110: current test individual_dataloader is aebad_S_AeBAD_S.\n",
      "[02/29 07:46:03][INFO] train.py:  111: the test data in current individual_dataloader aebad_S_AeBAD_S are 689.\n",
      "[02/29 07:46:03][INFO] train.py:  113: Computing evaluation metrics.\n",
      "[02/29 07:52:36][INFO] common.py:  258: image save complete!\n",
      "[02/29 07:52:37][INFO] train.py:  135: aebad_S_AeBAD_S's Image_Level AUROC is 84.800000.%\n",
      "[02/29 07:52:37][INFO] train.py:  138: aebad_S_AeBAD_S's Full_Pixel_Level AUROC is 93.392919.%\n",
      "[02/29 07:52:37][INFO] train.py:  142: aebad_S_AeBAD_S's per-region-overlap (PRO) AUROC is 90.100000.%\n",
      "[02/29 07:52:37][INFO] train.py:  105: current domain shift mode is background!\n",
      "[02/29 07:52:37][INFO] train.py:  110: current test individual_dataloader is aebad_S_AeBAD_S.\n",
      "[02/29 07:52:37][INFO] train.py:  111: the test data in current individual_dataloader aebad_S_AeBAD_S are 305.\n",
      "[02/29 07:52:37][INFO] train.py:  113: Computing evaluation metrics.\n",
      "[02/29 07:54:37][INFO] common.py:  258: image save complete!\n",
      "[02/29 07:54:37][INFO] train.py:  135: aebad_S_AeBAD_S's Image_Level AUROC is 85.000000.%\n",
      "[02/29 07:54:37][INFO] train.py:  138: aebad_S_AeBAD_S's Full_Pixel_Level AUROC is 88.323994.%\n",
      "[02/29 07:54:37][INFO] train.py:  142: aebad_S_AeBAD_S's per-region-overlap (PRO) AUROC is 90.900000.%\n",
      "[02/29 07:54:37][INFO] train.py:  105: current domain shift mode is illumination!\n",
      "[02/29 07:54:37][INFO] train.py:  110: current test individual_dataloader is aebad_S_AeBAD_S.\n",
      "[02/29 07:54:37][INFO] train.py:  111: the test data in current individual_dataloader aebad_S_AeBAD_S are 273.\n",
      "[02/29 07:54:37][INFO] train.py:  113: Computing evaluation metrics.\n",
      "[02/29 07:56:33][INFO] common.py:  258: image save complete!\n",
      "[02/29 07:56:33][INFO] train.py:  135: aebad_S_AeBAD_S's Image_Level AUROC is 89.800000.%\n",
      "[02/29 07:56:33][INFO] train.py:  138: aebad_S_AeBAD_S's Full_Pixel_Level AUROC is 92.829416.%\n",
      "[02/29 07:56:33][INFO] train.py:  142: aebad_S_AeBAD_S's per-region-overlap (PRO) AUROC is 91.200000.%\n",
      "[02/29 07:56:33][INFO] train.py:  105: current domain shift mode is view!\n",
      "[02/29 07:56:33][INFO] train.py:  110: current test individual_dataloader is aebad_S_AeBAD_S.\n",
      "[02/29 07:56:33][INFO] train.py:  111: the test data in current individual_dataloader aebad_S_AeBAD_S are 372.\n",
      "[02/29 07:56:33][INFO] train.py:  113: Computing evaluation metrics.\n",
      "[02/29 07:59:35][INFO] common.py:  258: image save complete!\n",
      "[02/29 07:59:35][INFO] train.py:  135: aebad_S_AeBAD_S's Image_Level AUROC is 80.400000.%\n",
      "[02/29 07:59:35][INFO] train.py:  138: aebad_S_AeBAD_S's Full_Pixel_Level AUROC is 89.026129.%\n",
      "[02/29 07:59:35][INFO] train.py:  142: aebad_S_AeBAD_S's per-region-overlap (PRO) AUROC is 86.300000.%\n",
      "[02/29 07:59:35][INFO] train.py:  145: Method training phase complete!\n",
      "[02/29 07:59:35][INFO] train.py:  148: Mean AUROC is 85.000000.%\n",
      "[02/29 07:59:35][INFO] train.py:  148: Mean Pixel-AUROC is 90.893114.%\n",
      "[02/29 07:59:35][INFO] train.py:  148: Mean per-region-overlap (PRO) is 89.625000.%\n",
      "[02/29 07:59:35][INFO] main.py:   42: Main function complete!\n"
     ]
    }
   ],
   "source": [
    "### Running the MMR program\n",
    "! /notebooks/MMR/AeBAD_S_run.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a08079-88eb-4479-a5e6-7cf63ee491d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
